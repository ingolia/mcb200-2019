{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allele-Specific Expression\n",
    "\n",
    "RNA sequencing can distinguish transcripts expressed from different copies of genes on homologous chromosomes when single-nucleotide polymorphisms (perhaps silent) distinguish the two alleles. Linkage between these distinctive SNPs and _cis_-regulatory sequences can provide information on regulatory variation within a shared cellular context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Hypothesis Testing\n",
    "\n",
    "The null hypothesis in allele-specific expression analysis is that the alleles are expressed equally and so each read is equally likely to be derived from each allele.\n",
    "\n",
    "Here, we'll take two approaches to get a _p_ value for the null hypothesis of equal expression in situations where just 25% of the reads come from one allele and 75% from the other. We'll look at this with just 8 reads, with 32 reads, and then with 100 reads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Testing\n",
    "\n",
    "First, we'll generate many random sets of data according to the null model and look at the distribution of allele skew in these random data. Our approach to generating random sets of reads is simple: we choose randomly between `0` and `1`, and then count how often we choose `1` by summing the results of this random choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "reads = np.random.choice(np.array([0, 1]), 8)\n",
    "print(reads)\n",
    "print(sum(reads))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Complete the work below to generate 10,000 random samples of 8 reads each, and tabulate how many random samples have zero, one, ..., eight reads from that sample. Print the counts, and then plot the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_counts_8 = np.zeros(9)\n",
    "for i in range(0,10000):\n",
    "    n_reads = ...\n",
    "    allele_counts_8[n_reads] += 1\n",
    "print(allele_counts_8)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** In what fraction of random samples do you see 25% or fewer `1` reads? What can you conclude from seeing this kind of skew in a sample of 8 reads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Now repeat the same analysis, for 32 reads per random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_counts_32 = ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** In what fraction of 32-read random samples do you see 25% or fewer `1` reads? What can you conclude from seeing this kind of skew in a sample of 32 reads? Are there any concerns that might arise in running this analysis genome-wide?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, read number has a big impact on different outcomes. \n",
    "\n",
    "**Exercise** Complete the function below that runs the entire allele skew analysis using the number of reads as an input parameter, and then run it for 32 and 100 reads. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allele_skew(num_reads):\n",
    "    allele_counts = ...\n",
    "    for i in range(0,10000):\n",
    "        ...\n",
    "    print(allele_counts)\n",
    "    plt.figure()\n",
    "    plt.plot(allele_counts)\n",
    "    return ...\n",
    "print(allele_skew(32))\n",
    "print(allele_skew(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial Distribution\n",
    "\n",
    "There is probably a small but non-zero odds of getting a 25% skew in a 100-read sample -- but we would need to generate a lot of random samples in order to figure out exactly how small. Instead, we could model the number of reads according to the binomial distribution. This isn't always a fair description of biological data, but it's a reasonable starting point here.\n",
    "\n",
    "Below, we use the binomial probability distribution to plot the _expected_ distribution of counts on top of the actual random sample from our `allele_skew` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binom\n",
    "allele_skew(32)\n",
    "x = np.arange(0,33)\n",
    "plt.plot(binom.pmf(x, 32, 0.5) * 10000, 'o-r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(binom.pmf(range(0,9), 32, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** Compute the likelihood of getting 25 _or fewer_ `1` reads. How many random samples would you typically need to see one skewed this much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation\n",
    "\n",
    "Instead of simply testing whether allele expression is even, we want to _estimate_ the relative skew in expression. To do this, we will start by making a graph where we consider all possible bias values, and then figure out the likelihood function P( 8 reads out of 32 | bias ). We'll use the `binom.pmf` function again, but now we'll consider many different values for the 3rd _p_ parameter instead of the first one.\n",
    "\n",
    "This graph looks similar to others that we've made, but the axes are different -- we'll add x and y axis labels to emphasize this difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = np.arange(0,1,0.01)\n",
    "plt.plot(bias, binom.pmf(8, 32, bias))\n",
    "plt.xlabel('Allele bias')\n",
    "plt.ylabel('P(8 reads / 32 total)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed before, we often want to work with log likelihood functions. In fact, `binom` has the built-in ability to give us a log probability that will be numerically stable when the actual likelihood is a very tiny number, using the `logpmf` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, binom.logpmf(8, 32, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot, the likelihood function looks pretty flat around 0.25, but we might want to adjust the y-axis to focus on the region of high likelihood -- the default puts a lot of emphasis on parts of the plot where the likelihood is very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(x, binom.logpmf(8, 32, x))\n",
    "plt.axis([0.0, 1.0, -10, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find the point on the x-axis where the likelihood is maximized. We can probably guess that this will happen at 0.25, but we can use algorithms from Scipy to find the best likelihood. These methods are typically expressed in terms of _minimization_, and so we'll minimize the negative log likelihood which is equivalent to finding the maximum of the likelihood.\n",
    "\n",
    "To do this, we define a function to compute the negative log likelihood, called `negloglik`, and then use `minimize_scalar` from `scipy.optimize` to find the allele skew value that maximizes the likelihood of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "def negloglik(bias):\n",
    "    return -binom.logpmf(8, 32, bias)\n",
    "mle = minimize_scalar(negloglik, bounds=(0,1), method='bounded')\n",
    "print(mle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The width of the likelihood peak can be used to compute a confidence interval. For a 95% confidence interval, we find the range of values where the log likelihood is within 1.92 of the best log likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_opt = mle.x\n",
    "loglik_opt = binom.logpmf(8, 32, bias_opt)\n",
    "print(loglik_opt, loglik_opt - 1.92)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this in a brute-force sort of way -- start at the best bias value and keep increasing it until the log likelihood drops off too much:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = bias_opt\n",
    "while binom.logpmf(8, 32, upper) > loglik_opt - 1.92:\n",
    "    upper += 0.001\n",
    "print(upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternately, we can use algorithms in Python to solve for the point where the log likelihood crosses our threshold. That is, we want to solve for _u_ where\n",
    "```\n",
    "lnP(8 reads out of 32 | bias = u) = loglik_opt - 1.92\n",
    "```\n",
    "or\n",
    "```\n",
    "lnP(8 reads out of 32 | bias = u) - loglik_opt + 1.92 = 0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import root_scalar\n",
    "def confint(u):\n",
    "    return binom.logpmf(8, 32, u) - loglik_opt + 1.92\n",
    "upper_ci = root_scalar(confint, bracket=[bias_opt, 1.0])\n",
    "print(upper_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use the same trick to find the lower bound of the confidence interval by looking below bias_opt -- between 0 and bias_opt -- rather than above bias_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_ci = root_scalar(confint, bracket=[0.0, bias_opt])\n",
    "print(lower_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then find the overall confidence interval for our estimate, based on the shape of the likelihood function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lower_ci.root, upper_ci.root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum A Posteriori Estimation\n",
    "\n",
    "**Exercise** Below, plot the log likelihood functions for:\n",
    "* 2 reads out of 8\n",
    "* 8 reads out of 32\n",
    "* 25 reads out of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,1,0.01)\n",
    "plt.plot(...)\n",
    "...\n",
    "plt.axis([0,1,-10,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
